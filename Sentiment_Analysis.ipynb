{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "UeY_6KCdU5q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Configs"
      ],
      "metadata": {
        "id": "HuWqiZ6mVcZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# setup device agnostic code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ],
      "metadata": {
        "id": "KObSJWbFVcb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset (IMDB from huggingface)"
      ],
      "metadata": {
        "id": "jKfQC1XaVce4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "train_texts = dataset['train']['text']\n",
        "train_labels = dataset['train']['label']\n",
        "test_texts  = dataset['test']['text']\n",
        "test_labels  = dataset['test']['label']"
      ],
      "metadata": {
        "id": "rbKbsWu5Vch4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train size: {len(train_texts)}')\n",
        "print(f'Test size: {len(test_texts)}')\n",
        "train_texts[1] , train_labels[1]"
      ],
      "metadata": {
        "id": "eYaDXscNVckw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "KpPQ8WMmVcnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text cleaning utility\n",
        "def clean_text(string):\n",
        "  string = string.lower()\n",
        "  string = re.sub(r\"https\\S+\",\"\",string)\n",
        "  string = re.sub(r\"@\\w+\", \"\", string)\n",
        "  string = re.sub(r\"[^a-z0-9\\s']\",\" \",string)\n",
        "  string = re.sub(r\"\\s+\",\" \",string).strip()\n",
        "\n",
        "  return string"
      ],
      "metadata": {
        "id": "gI0u39t9VcqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying utility on train-test data\n",
        "train_texts = [clean_text(t) for t in train_texts]\n",
        "test_texts = [clean_text(t) for t in test_texts]"
      ],
      "metadata": {
        "id": "qjmOsOMZVctI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization & Vocabulary"
      ],
      "metadata": {
        "id": "Rs_ryiX7YQnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def build_vocab(texts,min_freq = 2, max_size = 200000):\n",
        "  counter = Counter()\n",
        "  for t in texts:\n",
        "    counter.update(t.split())\n",
        "  most_common = [w for w, c in counter.most_common(max_size) if c >=min_freq]\n",
        "  itos = [\"<PAD>\",\"<OOV>\"] + most_common\n",
        "  stoi = {w:i for i , w in enumerate(itos)}\n",
        "  return stoi , itos\n",
        "\n",
        "stoi , itos = build_vocab(train_texts)\n",
        "vocab_size = len(stoi)\n",
        "print(\"Vocab Size: \", vocab_size)"
      ],
      "metadata": {
        "id": "Ya9Q0X3lYQjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequence(texts,stoi):\n",
        "  seqs = []\n",
        "  for t in texts:\n",
        "    seq = [stoi.get(w,stoi[\"<OOV>\"]) for w in t.split()]\n",
        "    seqs.append(torch.tensor(seq, dtype= torch.long))\n",
        "  return seqs\n",
        "\n",
        "train_seq = texts_to_sequence(train_texts,stoi)\n",
        "test_seq = texts_to_sequence(test_texts , stoi)"
      ],
      "metadata": {
        "id": "kpu0jOmSYQfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset & DataLoader"
      ],
      "metadata": {
        "id": "gnYSIiQhYQac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self,seqs, labels):\n",
        "    self.seqs = seqs\n",
        "    self.labels = labels\n",
        "  def __len__(self):\n",
        "    return len(self.seqs)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.seqs[idx], torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "\n",
        "def collate_fn(batch):\n",
        "  seqs , labels = zip(*batch)\n",
        "  seqs_padded = pad_sequence(seqs, batch_first=True, padding_value= 0)\n",
        "  lengths = torch.tensor([len(s) for s in seqs])\n",
        "  labels = torch.stack(labels)\n",
        "  return seqs_padded, lengths, labels\n"
      ],
      "metadata": {
        "id": "jWW-oN8WYQXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TextDataset(train_seq,train_labels)\n",
        "test_ds = TextDataset(test_seq, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_ds,\n",
        "                          batch_size=64,\n",
        "                          shuffle=True,\n",
        "                          collate_fn= collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_ds,\n",
        "                          batch_size=64,\n",
        "                          collate_fn= collate_fn)"
      ],
      "metadata": {
        "id": "AJbUmcbPYQT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model (LSTM)"
      ],
      "metadata": {
        "id": "nIF7cm_5YQRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_dim = 128, hidden_dim = 128, n_layers = 1,\n",
        "               bidirectional = True, dropout = 0.5):\n",
        "\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_dim , padding_idx=0)\n",
        "    self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers= n_layers,\n",
        "                        batch_first = True, bidirectional=bidirectional,\n",
        "                        dropout= dropout if n_layers > 1 else 0)\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(hidden_dim * (2 if bidirectional else 1 ), 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(64,1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x, lengths = None):\n",
        "    emb = self.emb(x)\n",
        "    out , (h,c) = self.lstm(emb)\n",
        "    h_last = torch.cat((h[-2], h[-1]), dim = 1) if self.lstm.bidirectional else h[-1]\n",
        "    logits = self.fc(h_last)\n",
        "    return logits.squeeze(1)\n",
        ""
      ],
      "metadata": {
        "id": "rjVF33-9YQOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}